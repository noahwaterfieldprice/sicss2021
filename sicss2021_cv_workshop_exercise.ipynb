{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# !pip3 install ipywidgets\n",
    "# !pip3 install loguru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SICSS 2021: ML and computer vision workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we train neural networks for image classification using the CIFAR10 dataset.\n",
    "\n",
    "We aim to cover:\n",
    "* Different network architectures\n",
    "* Different opimization methods\n",
    "* Hyperparameter optimization\n",
    "* Preventing overfitting\n",
    "* Leveraging pretrained models\n",
    "* Data augmentation\n",
    "* Evaluating trained models\n",
    "* Model introspection\n",
    "\n",
    "\n",
    "Things to note:\n",
    "* For simplicity in here we have no *validation* set. We use the test set directly for valiation. By doing hyperparameter optimization in this way, we are likely overfitting to the test set and so would need an independent hold-out dataset to truly test generalisation.\n",
    "* The network performances are not representative of what is achieveable. Due to restricted hardware, we are running for a few epochs on a limited dataset. In reality the state-of-the-art accuracy on CIFAR10 to is ~100%.\n",
    "* Try not to be overwhelmed with amount of machinery surrounding the training in this notebook. The vast majority of it can be ignored and left as is. When doing these kind of tasks yourself, there are many libraries to handle a lot of these things for you including [ignite](https://pytorch.org/ignite/index.html), [pytorch-lightning](https://www.pytorchlightning.ai/) and [fastai](https://www.fast.ai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {},
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import sys\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "\n",
    "import IPython.display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.decomposition\n",
    "import sklearn.manifold\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "import torchvision as tv\n",
    "import tqdm.notebook\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global constants/defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Very important cell** Don't worry if not all of these parameters sense yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device_type} device\")\n",
    "DEVICE = torch.device(device_type)\n",
    "\n",
    "# Set to < 1 to train on subset of data to speed up training\n",
    "# during development (will also increase overfitting..)\n",
    "TRAIN_DATA_SAMPLE_FRAC = 0.2\n",
    "LOG_INTERVAL = int(500 * TRAIN_DATA_SAMPLE_FRAC)  # Batch iterations\n",
    "\n",
    "# Hyper parameters\n",
    "N_EPOCHS = 8\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 1e-3\n",
    "LOSS_FN = torch.nn.CrossEntropyLoss()\n",
    "OPTIMIZER_TYPE = torch.optim.SGD\n",
    "MOMENTUM = 0.9  # See https://distill.pub/2017/momentum/\n",
    "WEIGHT_DECAY = 0  # Equivalent to L2 regularisation\n",
    "AUGMENTATIONS = tv.transforms.Compose(\n",
    "    [\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting / logging setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign some sensible defaults plotting and logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-talk\")\n",
    "matplotlib.rcParams.update({\"axes.grid\": True, \"grid.alpha\": 0.3})\n",
    "\n",
    "LOG_FORMAT = (\n",
    "    \"<fg #01665E>{time:YYYY-MM-DD HH:mm:ss.SSS}</> | \"\n",
    "    \"<level>{level}</level> | \"\n",
    "    \"<level><n>{message}</n></level>\"\n",
    ")\n",
    "logger.remove()\n",
    "logger.add(\n",
    "    sink=sys.stdout,\n",
    "    format=LOG_FORMAT,\n",
    "    colorize=True,\n",
    "    backtrace=True,\n",
    "    level=\"INFO\",\n",
    "    diagnose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_msg(message: str) -> str:\n",
    "    \"\"\"Pad message to constant width with '=' symbol.\"\"\"\n",
    "    message_with_spaces = f\" {message} \"\n",
    "    return f\"{message_with_spaces:=^100}\"\n",
    "\n",
    "\n",
    "def generate_train_log_message(\n",
    "    batch_num: int, batches_per_epoch: int, metrics: Dict[str, float]\n",
    ") -> str:\n",
    "    return (\n",
    "        f\"<b>Training</b>: \"\n",
    "        f\"Batch {batch_num:04d}/{batches_per_epoch:04d} \"\n",
    "        f\"({batch_num / batches_per_epoch * 100:03.0f}%) | \"\n",
    "        f\"{generate_metrics_log_message(metrics)}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_test_log_message(metrics: Dict[str, float]) -> str:\n",
    "    return (\n",
    "        f\"<b>Testing</b>: {'-' * 23} | \"\n",
    "        f\"<b>{generate_metrics_log_message(metrics)}</b>\"\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_metrics_log_message(metrics: Dict[str, float]) -> str:\n",
    "    colour_cycle = itertools.cycle([\"light-blue\", \"light-green\"])\n",
    "    metrics_info = []\n",
    "    for (metric_name, metric), colour in zip(metrics.items(), colour_cycle):\n",
    "        metric_name_pretty = _METRIC_FORMAT[metric_name][\"pretty_name\"]\n",
    "        formatted_value = _METRIC_FORMAT[metric_name][\"fmt\"].format(metric)\n",
    "        metrics_info.append(\n",
    "            f\"<{colour}>{metric_name_pretty}: \" f\"{formatted_value}</{colour}>\"\n",
    "        )\n",
    "    metrics_log_message = \" | \".join(metrics_info)\n",
    "    return metrics_log_message\n",
    "\n",
    "\n",
    "_METRIC_FORMAT = {\n",
    "    \"top1accuracy\": {\"pretty_name\": \"Top-1 Accuracy\", \"fmt\": \"{:04.1f}%\"},\n",
    "    \"top3accuracy\": {\"pretty_name\": \"Top-3 Accuracy\", \"fmt\": \"{:04.1f}%\"},\n",
    "    \"loss\": {\"pretty_name\": \"Average Loss\", \"fmt\": \"{:.4f}\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataset(\n",
    "    dataset: torch.utils.data.Dataset, frac: float\n",
    ") -> torch.utils.data.Subset:\n",
    "    \"\"\"\n",
    "    Return a random subset of a dataset.\n",
    "    \n",
    "    Stratified sampling is used so the 10 classes are equally \n",
    "    represented in the sample.\n",
    "    \n",
    "    Args:\n",
    "        dataset: The pytorch dataset to sample from.\n",
    "        frac: A number between 0 and 1 specifying the size of the sample \n",
    "            as a fraction of the original dataset size.\n",
    "    \"\"\"\n",
    "    assert 0 < frac <= 1\n",
    "    sample_indices = []\n",
    "    class_indices = collections.defaultdict(list)\n",
    "    for idx, label in enumerate(dataset.targets):\n",
    "        class_indices[label].append(idx)\n",
    "    class_indices = {label: indices for label, indices in sorted(class_indices.items())}\n",
    "\n",
    "    for _, indices in class_indices.items():\n",
    "        class_sample_size = int(frac * len(indices))\n",
    "        class_sample_indices = np.random.choice(indices, class_sample_size)\n",
    "        sample_indices.extend(class_sample_indices)\n",
    "    np.random.shuffle(sample_indices)\n",
    "    return torch.utils.data.Subset(dataset, sample_indices)\n",
    "\n",
    "\n",
    "def get_cifar10_dataloader(\n",
    "    is_train: bool,\n",
    "    augmentations: tv.transforms.Compose,\n",
    "    batch_size: int,\n",
    "    data_sample_frac: float = 1,\n",
    ") -> torch.utils.data.DataLoader:\n",
    "    \"\"\"Return CIFAR10 dataloader with convenient defaults.\"\"\"\n",
    "    dataset = tv.datasets.CIFAR10(\n",
    "        root=\"data\",\n",
    "        train=is_train,\n",
    "        download=True,\n",
    "        transform=augmentations,\n",
    "    )\n",
    "\n",
    "    if data_sample_frac < 1:\n",
    "        assert 0 < data_sample_frac < 1\n",
    "        dataset = sample_dataset(dataset, data_sample_frac)\n",
    "\n",
    "    return torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(output: Dict[str, List[float]]) -> Dict[str, float]:\n",
    "    \"\"\"Calculate classification metrics from standard output.\"\"\"\n",
    "    metrics = {}\n",
    "    metrics[\"top1accuracy\"] = (\n",
    "        sklearn.metrics.top_k_accuracy_score(output[\"y\"], output[\"y_pred\"], k=1) * 100\n",
    "    )\n",
    "    metrics[\"top3accuracy\"] = (\n",
    "        sklearn.metrics.top_k_accuracy_score(output[\"y\"], output[\"y_pred\"], k=3) * 100\n",
    "    )\n",
    "    metrics[\"loss\"] = np.mean(output[\"loss\"]) / BATCH_SIZE\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def accumulate_dict(\n",
    "    accumulator: Dict[str, List[float]],\n",
    "    update: Dict[str, Union[torch.Tensor, List[float], float]],\n",
    ") -> None:\n",
    "    \"\"\"Update each list in an accumulator dict with values from update.\"\"\"\n",
    "    for key, value in update.items():\n",
    "        try:\n",
    "            value_length = len(value)\n",
    "        except TypeError:  # is scalar or 0-d tensor e.g loss\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                value = value.item()\n",
    "            accumulator[key].append(value)\n",
    "        else:  # Is list or torch tensor\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                value = value.tolist()\n",
    "            accumulator[key].extend(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_metrics(metrics: Dict[str, List[float]]) -> plt.Figure:\n",
    "    PLOT_KWARGS = {\"alpha\": 0.7, \"linewidth\": 2, \"marker\": \"o\"}\n",
    "\n",
    "    fig, (loss_ax, acc_ax) = plt.subplots(\n",
    "        nrows=2, sharex=True, figsize=(12, 10), constrained_layout=True\n",
    "    )\n",
    "    for subset in (\"train\", \"test\"):\n",
    "        loss_ax.plot(\n",
    "            metrics[subset][\"iteration\"],\n",
    "            metrics[subset][\"loss\"],\n",
    "            label=subset,\n",
    "            **PLOT_KWARGS,\n",
    "        )\n",
    "    loss_ax.set_ylabel(\"Average loss\")\n",
    "    loss_ax.legend()\n",
    "\n",
    "    for subset in (\"train\", \"test\"):\n",
    "        acc_ax.plot(\n",
    "            metrics[subset][\"iteration\"],\n",
    "            metrics[subset][\"top1accuracy\"],\n",
    "            label=subset,\n",
    "            **PLOT_KWARGS,\n",
    "        )\n",
    "\n",
    "    acc_ax.set_ylabel(\"Accuracy\")\n",
    "    acc_ax.set_xlabel(\"Batches\")\n",
    "    return fig\n",
    "\n",
    "def display_prediction_images(df: pd.DataFrame) -> plt.Figure:\n",
    "    fig, (img_axes, score_axes) = plt.subplots(\n",
    "        nrows=2,\n",
    "        ncols=len(df),\n",
    "        figsize=(1.7 * len(df), 4),\n",
    "        gridspec_kw={\"wspace\": 0.1, \"height_ratios\": [1, 1.2], \"hspace\": 0.2},\n",
    "        sharey=\"row\",\n",
    "    )\n",
    "    for img_ax, score_ax, (index, row) in zip(img_axes.flat, score_axes.flat, df.iterrows()):\n",
    "        image = test_data[index][0].numpy().transpose(1, 2, 0) / 2 + 0.5\n",
    "        scores = row.loc[\"score0\":\"score9\"].values\n",
    "        is_correct = np.argmax(scores) == row.label\n",
    "        symbol = \"✔\" if is_correct else \"✘\"\n",
    "        # Add image to plot\n",
    "        img_ax.imshow(image)\n",
    "        img_ax.text(\n",
    "            0.5,\n",
    "            1.05,\n",
    "            f\"{CLASSES[row.label.astype(int)]} {symbol}\",\n",
    "            transform=img_ax.transAxes,\n",
    "            horizontalalignment=\"center\",\n",
    "            size=14,\n",
    "        )\n",
    "        img_ax.text(\n",
    "            0.5,\n",
    "            -0.15,\n",
    "            index,\n",
    "            transform=img_ax.transAxes,\n",
    "            horizontalalignment=\"center\",\n",
    "            size=14,\n",
    "        )\n",
    "        img_ax.axis(\"off\")\n",
    "        # Add score distribution to plot\n",
    "        score_ax.barh(CLASSES, scores)\n",
    "        score_ax.set_xlim(0, 1)\n",
    "        score_ax.get_xaxis().set_visible(False)\n",
    "        for border in (\"top\", \"right\", \"bottom\"):\n",
    "            score_ax.spines[border].set_visible(False)\n",
    "        score_ax.grid(False)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def show_svg(filepath: str) -> None:\n",
    "    IPython.display.display(IPython.display.SVG(filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "PyTorch has two [primitives to work with data](https://pytorch.org/docs/stable/data.html) : \n",
    "``torch.utils.data.DataLoader`` and ``torch.utils.data.Dataset``. \n",
    "\n",
    "* A ``Dataset`` stores the samples (in this case images) and their corresponding labels. It can also optionally perform an augmentation operation to each sample/label upon loading. \n",
    "* A``DataLoader`` wraps an iterable around the ``Dataset`` and handles the batching and, optionally, sampling of the dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "PyTorch offers domain-specific libraries such as [TorchText][],\n",
    "[TorchVision][], and [TorchAudio][], all of which include datasets. For\n",
    "this tutorial, we will be using a TorchVision dataset.\n",
    "\n",
    "The `torchvision.datasets` module contains `Dataset` objects for many\n",
    "real-world vision data like CIFAR, COCO ([full list here][]). In this\n",
    "tutorial, we use the CIFAR10 dataset. Every TorchVision `Dataset`\n",
    "includes two arguments: `transform` and `target_transform` to modify the\n",
    "samples and labels respectively.\n",
    "\n",
    "  [TorchText]: https://pytorch.org/text/stable/index.html\n",
    "  [TorchVision]: https://pytorch.org/vision/stable/index.html\n",
    "  [TorchAudio]: https://pytorch.org/audio/stable/index.html\n",
    "  [full list here]: https://pytorch.org/docs/stable/torchvision/datasets.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {},
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "print(pad_msg(\"Training data\"))\n",
    "training_data = tv.datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=AUGMENTATIONS,\n",
    ")\n",
    "print(training_data)\n",
    "\n",
    "\n",
    "# Download test data from open datasets.\n",
    "print(pad_msg(\"Test data\"))\n",
    "test_data = tv.datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=AUGMENTATIONS,\n",
    ")\n",
    "print(test_data)\n",
    "\n",
    "CLASSES = (\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "We pass the ``Dataset`` as an argument to ``DataLoader``. This wraps an iterable over our dataset, and supports\n",
    "automatic batching, sampling, shuffling and multiprocess data loading. Here the batch size is defined above, i.e. each element \n",
    "in the dataloader iterable will return a batch of `BATCH_SIZE` images and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {},
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = get_cifar10_dataloader(\n",
    "    is_train=True, \n",
    "    augmentations=AUGMENTATIONS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    train_data_sample_frac=TRAIN_DATA_SAMPLE_FRAC\n",
    ")\n",
    "test_dataloader = get_cifar10_dataloader(\n",
    "    is_train=False, \n",
    "    augmentations=AUGMENTATIONS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    train_data_sample_frac=TRAIN_DATA_SAMPLE_FRAC\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, y in test_dataloader:\n",
    "    print(\"Shape of image batch [B, C, H, W]: \", images.shape)\n",
    "    print(\"Shape of y (labels) batch: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_dataloader))\n",
    "fig, ax = plt.subplots(figsize=(10.5, 5))\n",
    "grid = tv.utils.make_grid(images)\n",
    "grid = grid / 2 + 0.5  # undo normalisation\n",
    "ax.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "ax.axis(\"off\")\n",
    "print(\" \".join(\"%8s\" % CLASSES[labels[j]] for j in range(BATCH_SIZE // 2)))\n",
    "print(\" \".join(\"%8s\" % CLASSES[labels[j]] for j in range(BATCH_SIZE // 2, BATCH_SIZE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "Read more about loading data in PyTorch: https://pytorch.org/tutorials/beginner/basics/data_tutorial.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## Optimizing the Model Parameters\n",
    "\n",
    "To train a model, we need a [loss function][] and an [optimizer][].\n",
    "\n",
    "  [loss function]: https://pytorch.org/docs/stable/nn.html#loss-functions\n",
    "  [optimizer]: https://pytorch.org/docs/stable/optim.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and \n",
    "backpropagates the prediction error to adjust the model's parameters. \n",
    "\n",
    "Training a model is an iterative process; in each iteration (or **batch**), the model makes a guess about the output, calculates the error in its guess (**loss**), collects the derivatives of the error with respect to its parameters, and optimizes these parameters using gradient descent. For a more detailed walkthrough of this process, check out [this video](https://www.youtube.com/watch?v=tIeHLnjs5U8) on backpropagation from 3Blue1Brown.\n",
    "\n",
    "Iterating over the entire dataset once is known as an **epoch**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {},
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train_step(\n",
    "    images: torch.Tensor,  # shape B x C x H x W\n",
    "    y: torch.tensor,  # shape B\n",
    "    model: torch.nn.Module,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    ") -> Dict[str, torch.Tensor]:  # FILL THIS IN\n",
    "    \"\"\"\n",
    "    Logic for a single training batch iteration.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with the model predictions \"y_pred\", corresponding\n",
    "        class labels \"y\", and the loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    # First put the model in training mode\n",
    "\n",
    "    # Then reset the optimizer gradients (calculated in any previous batches)\n",
    "\n",
    "    # Then move the images and labels to the torch device\n",
    "\n",
    "    # Calculate predictions and compute the loss\n",
    "\n",
    "    # Backpropagate the loss through the network and update model parameters with optimizer\n",
    "    \n",
    "    # Return a dictionary with the predictions, labels and batch loss\n",
    "    # return {\"y_pred\": ..., \"y\": ..., \"loss\": ...}\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    model: torch.nn.Module,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    log_interval: int,\n",
    "    lr_scheduler: torch.optim.lr_scheduler._LRScheduler = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Train a pytorch model on the given data for a single epoch.\"\"\"\n",
    "    log_metrics_over_epoch = collections.defaultdict(list)\n",
    "    log_outputs = collections.defaultdict(list)\n",
    "\n",
    "    for batch_number, (images, y) in enumerate(dataloader, start=1):\n",
    "        batch_outputs = train_step(images, y, model, loss_fn, optimizer, device)\n",
    "\n",
    "        # Update optimizer learning rate\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        # Accumulate batch outputs over log interval\n",
    "        accumulate_dict(log_outputs, update=batch_outputs)\n",
    "        if batch_number % log_interval == 0:\n",
    "            log_metrics = calculate_metrics(log_outputs)\n",
    "            log_message = generate_train_log_message(\n",
    "                batch_number, len(dataloader), log_metrics\n",
    "            )\n",
    "            if lr_scheduler is not None:\n",
    "                log_message += f\" | lr: {lr_scheduler.get_last_lr()[0]:.5f}\"\n",
    "            logger.opt(colors=True).info(log_message)\n",
    "\n",
    "            # Accumulate log metrics for plotting\n",
    "            accumulate_dict(log_metrics_over_epoch, update=log_metrics)\n",
    "\n",
    "            # Reset log outputs to be accumulated over next log interval\n",
    "            log_outputs = collections.defaultdict(list)\n",
    "\n",
    "    return log_metrics_over_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "We also check the model's performance against the test dataset to ensure it is learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {},
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def test_step(\n",
    "    images: torch.Tensor,\n",
    "    y: torch.tensor,\n",
    "    model: torch.nn.Module,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    device: torch.device,\n",
    ") -> Dict[str, torch.Tensor]:  # FILL THIS IN\n",
    "    \"\"\"\n",
    "    Logic for a single test batch iteration.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with the model predictions \"y_pred\", corresponding class labels \"y\",\n",
    "        and the loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # First put the model in evaluation mode\n",
    "    with torch.no_grad(): # Ensure gradients are not computed\n",
    "        # Then move images and labels to torch device\n",
    "\n",
    "        # Calculate predictions and compute the loss\n",
    "        \n",
    "    # Return a dictionary with the predictions, labels and batch loss\n",
    "    \n",
    "    # return {\"y_pred\": ..., \"y\": ..., \"loss\": ...}\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def test_epoch(\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    model: torch.nn.Module,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    device: torch.device,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Evaluate model performance on given dataloader.\"\"\"\n",
    "    epoch_outputs = collections.defaultdict(list)\n",
    "    for images, y in dataloader:\n",
    "        batch_outputs = test_step(images, y, model, loss_fn, device)\n",
    "\n",
    "        # Accumulate batch outputs to calculate metrics\n",
    "        accumulate_dict(epoch_outputs, batch_outputs)\n",
    "\n",
    "    metrics = calculate_metrics(epoch_outputs)\n",
    "    logger.opt(colors=True).info(generate_test_log_message(metrics))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall training/testing function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "The training process is conducted over several iterations (*epochs*). During each epoch, the model learns \n",
    "parameters to make better predictions. We print the model's accuracy and loss at each epoch; we'd like to see the\n",
    "accuracy increase and the loss decrease with every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    model: torch.nn.Module,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    n_epochs: int = N_EPOCHS,\n",
    "    log_interval: int = LOG_INTERVAL,\n",
    "    lr_scheduler: torch.optim.lr_scheduler._LRScheduler = None,\n",
    ") -> Dict[str, Dict[str, List[float]]]:\n",
    "    metrics = {\n",
    "        \"train\": collections.defaultdict(list),\n",
    "        \"test\": collections.defaultdict(list),\n",
    "    }\n",
    "    # Test untrained model and accumulate metrics\n",
    "    initial_test_metrics = test_epoch(test_dataloader, model, loss_fn, device)\n",
    "    accumulate_dict(metrics[\"test\"], update=initial_test_metrics)\n",
    "    metrics[\"test\"][\"iteration\"].append(0)\n",
    "\n",
    "    # Train for specified number of epocchs\n",
    "    for epoch_num in range(1, n_epochs + 1):\n",
    "        logger.opt(colors=True).info(pad_msg(f\"<b>Epoch {epoch_num} / {n_epochs}</b>\"))\n",
    "        # Train model for single epoch\n",
    "        train_epoch_metrics = train_epoch(\n",
    "            train_dataloader,\n",
    "            model,\n",
    "            loss_fn,\n",
    "            optimizer,\n",
    "            device,\n",
    "            lr_scheduler=lr_scheduler,\n",
    "            log_interval=log_interval,\n",
    "        )\n",
    "        # Test current model\n",
    "        test_epoch_metrics = test_epoch(test_dataloader, model, loss_fn, device)\n",
    "\n",
    "        # Accumulate test and train metrics for epoch\n",
    "        accumulate_dict(metrics[\"train\"], update=train_epoch_metrics)\n",
    "        iteration_nums_for_train_metrics = [\n",
    "            (epoch_num - 1) * len(train_dataloader) + i * LOG_INTERVAL\n",
    "            for i in range(len(train_dataloader) // LOG_INTERVAL)\n",
    "        ]\n",
    "        metrics[\"train\"][\"iteration\"].extend(iteration_nums_for_train_metrics)\n",
    "        accumulate_dict(metrics[\"test\"], update=test_epoch_metrics)\n",
    "        metrics[\"test\"][\"iteration\"].append(epoch_num * len(train_dataloader))\n",
    "\n",
    "    logger.opt(colors=True).info(pad_msg(f\"<b>Training completed!</b>\"))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A naive approach - FCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naive approach may be to apply the most basic type of neural network to the problem, a so-called 'fully-connected' or 'dense' network. This approach is naive as it treats every pixel in the image as an independent 'feature', which ignores all the local-correlation information present in images. Furthermore, FCNNs tend have A LOT of parameters and are easy to overfit. \n",
    "\n",
    "Here we use a 3-layer network that goes from 3072 pixel values -> 256 -> 256 -> 10 classification predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_svg(\"figures/networks/fcnn.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "To define a neural network in PyTorch, we create a class that inherits\n",
    "from [nn.Module][]. We define the layers of the network in the\n",
    "`__init__` function and specify how data will pass through the network\n",
    "in the `forward` function. To accelerate operations in the neural\n",
    "network, we move it to the GPU if available.\n",
    "\n",
    "  [nn.Module]: https://pytorch.org/docs/stable/generated/torch.nn.Module.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {},
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class FullyConnectedNeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.linear_relu_stack = torch.nn.Sequential(\n",
    "            torch.nn.Linear(3 * 32 * 32, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 10),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "Read more about `building neural networks in PyTorch`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcnn = FullyConnectedNeuralNetwork().to(DEVICE)\n",
    "print(fcnn)\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in fcnn.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first test the model performance in its untrained state. Given there are 10, equally prevalent classes we would expect a random top-1 accuracy of ~10% and a top-3 accuracy of ~30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = test_epoch(\n",
    "    dataloader=test_dataloader,\n",
    "    model=fcnn,\n",
    "    loss_fn=LOSS_FN,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "fcnn_optimizer = OPTIMIZER_TYPE(\n",
    "    fcnn.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    momentum=MOMENTUM,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "fcnn_optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !Excercise!:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Complete the `train_step` function, which runs the model on a single training batch, computes the loss, updates the model parameters, and returns the results.\n",
    "* Complete the `test_step` functions, which runs the model on a single test batch, computes the loss and returns the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat model/optimizer initialistion to ensure starting from untrained\n",
    "# and avoid notebook-cell-execution-order-type errors\n",
    "fcnn = FullyConnectedNeuralNetwork().to(DEVICE)\n",
    "fcnn_optimizer = OPTIMIZER_TYPE(\n",
    "    fcnn.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    momentum=MOMENTUM,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "fcnn_metrics = train_model(\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    model=fcnn,\n",
    "    optimizer=fcnn_optimizer,\n",
    "    loss_fn=LOSS_FN,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_training_metrics(fcnn_metrics)\n",
    "fig.suptitle(\"FCNN training metrics\")\n",
    "fig.savefig(\"figures/plots/fcnn_training_metrics.png\", dpi=150, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !Exercise!:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you reduce the amount of overfitting and/or hopefully improve test performance with any of the following techniques?\n",
    "* Adding a dropout layer between the hidden layer and output layer\n",
    "* Increasing the weight decay in the optimizer\n",
    "* Using a different optimizer / altering the optimizer parameters\n",
    "* Changing the batch size\n",
    "* Adding batch normalisation layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An image-tailored approach - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_svg(\"figures/networks/cnn.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more suitable approach would be to use a CNN. Here we use a very simple CNN with 2 convolutional layers + max pooling, followed by 3 linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvolutionalNeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.features = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, 2),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(in_features=400, out_features=120),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=120, out_features=84),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.classifier = torch.nn.Linear(in_features=84, out_features=10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        features = self.features(x)\n",
    "        logits = self.classifier(features)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = ConvolutionalNeuralNetwork().to(DEVICE)\n",
    "print(cnn)\n",
    "print(f\"Num parameters: {sum(p.numel() for p in cnn.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how many fewer parameters the CNN has than the FCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking in 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important aspect of CNNs is how each of the operations transforms the shape of its input. \n",
    "\n",
    "The main two types of operation to be aware of are:\n",
    "* Convolutions: These can arbitrarily change the number of channels (or *depth*) and, depending on the kernel size, stride and padding, also alter in-plane (x/y) dimensions.\n",
    "* Pooling: A pooling operation will leave the number of channels unchanged but reduce (often by a factor of 2 or 3) the size of the in-plane (x/y) dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = torch.nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
    "conv2 = torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "max_pool = torch.nn.MaxPool2d(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, _ = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the network input is a batch of images with dimensions in the order: \n",
    "\n",
    "`batch_size` x `n_image_channels` x `image_height` x `image_width`\n",
    "\n",
    "The images in CIFAR10 are 32px x 32px RGB (i.e. 3 channel) images \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first convolution goes from the 3 image channels to 6 feature channels and a kernel size of 5x5. Without any padding, this should shave off 2 rows/columns each side of the H/W image dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1(images).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The next operation is a max-pooling operation with a kernel size of 2x2. This should simply reduce the H/W image dimensions by a factor of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pool(conv1(images)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second convolution goes from 6 to 16 feature channels with a kernel size of 5x5. Again, this should reduce the H/W dimensions by 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2(max_pool(conv1(images))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max pools will reduce H/W by a factor of 2 again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pool(conv2(max_pool(conv1(images)))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These 16 x 5 x 5 = 400 features are then flattened and used as input to the fully-connected latter part of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_optimizer = OPTIMIZER_TYPE(\n",
    "    cnn.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    momentum=MOMENTUM,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "print(cnn_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat model/optimizer initialistion to ensure starting from untrained\n",
    "# and avoid notebook-cell-execution-order-type errors\n",
    "cnn = ConvolutionalNeuralNetwork().to(DEVICE)\n",
    "cnn_optimizer = OPTIMIZER_TYPE(\n",
    "    cnn.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    momentum=MOMENTUM,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "# Train the model\n",
    "cnn_metrics = train_model(\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    model=cnn,\n",
    "    optimizer=cnn_optimizer,\n",
    "    loss_fn=LOSS_FN,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_training_metrics(cnn_metrics)\n",
    "fig.suptitle(\"CNN training metrics\")\n",
    "fig.savefig(\"figures/plots/cnn_training_metrics.png\", dpi=150, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !Exercise!:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you reduce the amount of overfitting and/or improve test performance with any of the following techniques?\n",
    "* Adding a dropout layer between the two linear layers\n",
    "* Increasing the weight decay in the optimizer\n",
    "* Using a different optimizer / altering the optimizer parameters\n",
    "* Changing the batch size\n",
    "* Using training data augmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrained models (often pretrained on the ImageNet dataset) are available from many sources. Here we use torchvision.models. These models have been trained on imagenet which has 1M images and 1000 different classes. This kind of pretraining allows you to leverage the hardware required to train these bigger models on much larger datasets on your own machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeeze_net = tv.models.squeezenet.squeezenet1_1(pretrained=True)\n",
    "squeeze_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although his model is pretrained, it is not pretrained for this classification task so we need to make some alterations to make it fit. The model architecture is conveniently divided into `squeezenet.features` which we can leave as they are and `squeezenet.classifier` which currently returns a 1000-way classifaction output (from ImageNet) that we need to swap out for a classifier that will work for CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeeze_net.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.5),\n",
    "    torch.nn.Conv2d(512, 256, kernel_size=1, stride=1),\n",
    "    torch.nn.ReLU(inplace=True),\n",
    "    torch.nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(256, 128),\n",
    "    torch.nn.ReLU(inplace=True),\n",
    "    torch.nn.Linear(128, 10),\n",
    ")\n",
    "\n",
    "squeeze_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this model was never trained on CIFAR10 plus we've just added a classifer that has untrained weights in it, we would expect the performance to be random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch(\n",
    "    test_dataloader, model=squeeze_net.to(DEVICE), loss_fn=LOSS_FN, device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeeze_net_optimzer = OPTIMIZER_TYPE(\n",
    "    squeeze_net.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM\n",
    ")\n",
    "squeeze_net_optimzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat model/optimizer initialistion to ensure starting from untrained\n",
    "# and avoid notebook-cell-execution-order-type errors\n",
    "squeeze_net = tv.models.squeezenet.squeezenet1_1(pretrained=True)\n",
    "squeeze_net.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(512, 256, kernel_size=1, stride=1),\n",
    "    torch.nn.ReLU(inplace=True),\n",
    "    torch.nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(256, 128),\n",
    "    torch.nn.ReLU(inplace=True),\n",
    "    torch.nn.Linear(128, 10),\n",
    ")\n",
    "squeeze_net = squeeze_net.to(DEVICE)\n",
    "\n",
    "# Freeze some parameters we don't want to optimize\n",
    "for param_name, param in squeeze_net.features.named_parameters():\n",
    "    if param_name.startswith(\"conv.0\"):\n",
    "        param.requires_grad = False\n",
    "\n",
    "squeeze_net_optimzer = OPTIMIZER_TYPE(\n",
    "    squeeze_net.parameters(),\n",
    "    lr=LEARNING_RATE / 5,  # Note the lower learning rate for fine tuning\n",
    "    momentum=MOMENTUM,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "one_cycle_lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    squeeze_net_optimzer,\n",
    "    max_lr=LEARNING_RATE / 5,  # Peak learning rate of cycle\n",
    "    epochs=N_EPOCHS * 2,\n",
    "    steps_per_epoch=len(train_dataloader),\n",
    ")\n",
    "\n",
    "squeezenet_metrics = train_model(\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    model=squeeze_net,\n",
    "    loss_fn=LOSS_FN,\n",
    "    optimizer=squeeze_net_optimzer,\n",
    "    device=DEVICE,\n",
    "    n_epochs=N_EPOCHS * 2,\n",
    "    lr_scheduler=one_cycle_lr_scheduler,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_training_metrics(squeezenet_metrics)\n",
    "fig.suptitle(\"Pretrained training metrics\")\n",
    "fig.savefig(\n",
    "    \"figures/plots/pretrained_training_metrics.png\", dpi=150, bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !Exercise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you reduce the amount of overfitting and/or hopefully improve test performance with any of the following techniques?\n",
    "* Changing which layers are frozen in the pretrained netowrk\n",
    "* Chaning the architecture of the new classifier we added\n",
    "* Any of the previous techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "# Saving/Loading models\n",
    "\n",
    "A common way to save a model is to serialize the internal state dictionary (containing the model parameters).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {},
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "torch.save(squeeze_net.state_dict(), \"squeeze_net_tuned.pth\")\n",
    "print(\"Saved PyTorch Model State to squeeze_net_tuned.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process for loading a model is to re-create the model structure and load\n",
    "the state dictionary into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {},
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "squeeze_net_loaded = tv.models.squeezenet.squeezenet1_1(pretrained=False)\n",
    "squeeze_net_loaded.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(512, 256, kernel_size=1, stride=1),\n",
    "    torch.nn.ReLU(inplace=True),\n",
    "    torch.nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(256, 128),\n",
    "    torch.nn.ReLU(inplace=True),\n",
    "    torch.nn.Linear(128, 10),\n",
    ")\n",
    "squeeze_net_loaded.load_state_dict(torch.load(\"squeeze_net_tuned.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model can now be used to make predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {},
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "example_idx = 205\n",
    "\n",
    "squeeze_net_loaded.eval()\n",
    "x, y = test_data[example_idx]\n",
    "with torch.no_grad():\n",
    "    pred = squeeze_net_loaded(torch.unsqueeze(x, dim=0))\n",
    "    predicted, actual = CLASSES[pred[0].argmax(0)], CLASSES[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the model scores and features on the test set we process the whole test_dataset with a batch_size of 1 and then construct a dataframe from these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    model: torch.nn.Module,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    device: torch.device,\n",
    ") -> pd.DataFrame:\n",
    "    assert dataloader.batch_size == 1\n",
    "    data = collections.defaultdict(list)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for image, label in tqdm.tqdm(dataloader):\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            logit_scores = model(image)\n",
    "            features = model.to(device).features(image)\n",
    "            loss = loss_fn(logit_scores, label).item()\n",
    "            softmax_scores = torch.nn.functional.softmax(logit_scores, dim=1).squeeze()\n",
    "            pred_label = softmax_scores.argmax(dim=0)\n",
    "            data[\"loss\"].append(loss)\n",
    "            data[\"pred_label\"].append(pred_label.item())\n",
    "            data[\"label\"].append(label.item())\n",
    "            for feauture_idx, feature in enumerate(features.squeeze()):\n",
    "                data[f\"feature{feauture_idx}\"].append(feature.item())\n",
    "            for class_idx, softmax_score in enumerate(softmax_scores):\n",
    "                data[f\"score{class_idx}\"].append(softmax_score.item())\n",
    "    return pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "test_dataloader_bs1 = get_cifar10_dataloader(\n",
    "    is_train=False, \n",
    "    augmentations=AUGMENTATIONS, \n",
    "    batch_size=1, # Batch size of 1 (to get loss per sample)\n",
    "    data_sample_frac=0.2\n",
    ")\n",
    "df = evaluate_model(test_dataloader_bs1, squeeze_net, LOSS_FN, DEVICE)  # Takes about 2 mins for squeezenet for data_sample_frac=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall top-1 accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = df.loc[:, \"score0\":\"score9\"]\n",
    "sklearn.metrics.top_k_accuracy_score(df.label, scores, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall top-3 accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = df.loc[:, \"score0\":\"score9\"]\n",
    "sklearn.metrics.top_k_accuracy_score(df.label, scores, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise examples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10_random = df.sample(10)\n",
    "fig = display_prediction_images(df_10_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10 examples with the highest loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "df_10_highest_loss = df.sort_values(by=\"loss\", ascending=False)[:10]\n",
    "fig = display_prediction_images(df_10_highest_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10 examples with the lowest loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10_lowest_loss = df.sort_values(by=\"loss\", ascending=True)[:10]\n",
    "fig = display_prediction_images(df_10_lowest_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise model feature distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "PERPLEXITY = 30\n",
    "TSNE_ITERS = 1000\n",
    "TSNE_LR = 300\n",
    "\n",
    "\n",
    "pca = sklearn.decomposition.PCA(n_components=30)\n",
    "tsne = sklearn.manifold.TSNE(\n",
    "    perplexity=PERPLEXITY, n_iter=TSNE_ITERS, learning_rate=TSNE_LR, verbose=True\n",
    ")\n",
    "features = df.loc[:, \"feature0\":\"feature511\"]\n",
    "pca_features = pca.fit_transform(features)\n",
    "tsne_coords = tsne.fit_transform(pca_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "for label, group_df in df.groupby(\"label\"):\n",
    "    ax.scatter(*tsne_coords[group_df.index].T, s=14, label=CLASSES[label], alpha=0.7)\n",
    "ax.legend()\n",
    "ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test-time Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_augmentations = tv.transforms.Compose(\n",
    "    [\n",
    "        tv.transforms.RandomVerticalFlip(),\n",
    "        tv.transforms.RandomHorizontalFlip(),\n",
    "        tv.transforms.RandomResizedCrop(size=32, scale=(0.8, 1)),\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "test_dataloader_bs1_augment = get_cifar10_dataloader(\n",
    "    is_train=False, \n",
    "    batch_size=1, \n",
    "    augmentations=test_augmentations, \n",
    "    data_sample_frac=0.2\n",
    ")\n",
    "\n",
    "test_aug_df = evaluate_model(\n",
    "    dataloader=test_dataloader_bs1_augment, \n",
    "    model=squeeze_net_loaded.to(DEVICE), \n",
    "    loss_fn=LOSS_FN, \n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall top-1 accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = df.loc[:, \"score0\":\"score9\"]\n",
    "sklearn.metrics.top_k_accuracy_score(df.label, scores, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall top-3 accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = df.loc[:, \"score0\":\"score9\"]\n",
    "sklearn.metrics.top_k_accuracy_score(df.label, scores, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_aug_dfs = []\n",
    "for _ in range(num_test_augmentations):\n",
    "test_aug_df = evaluate_model(\n",
    "    dataloader=test_dataloader_bs1_augment, \n",
    "    model=squeeze_net_loaded, \n",
    "    loss_fn=LOSS_FN, \n",
    "    device=DEVICE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation is ubiquitous technique in computer vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augmentations = tv.transforms.Compose(\n",
    "    [\n",
    "        tv.transforms.RandomVerticalFlip(),\n",
    "        tv.transforms.RandomHorizontalFlip(),\n",
    "        tv.transforms.RandomResizedCrop(size=32, scale=(0.8, 1)),\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another popular technique to improve prediction performance is to train an ensemble of models and combine their predictions. Although, there are many ways to create different models to ensemble, the easiest (but still very effective) method is just to repeat the training process multiple times. Optimization of neural networks is non-deterministic by nature so simply creating multiple model instances (each with a corresponding optimzer) and training each one gives you a good ensemble.\n",
    "\n",
    "Try training another few CNNs, running the evaluation on each and combining the scores (simply by taking the mean over the ensemble). How much does performance improve by? How does this vary by number of models in the ensemble?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
